{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 Second features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all data: (1000, 60)\n",
      "\n",
      "Categories Encoded:\n",
      "blues: 0\n",
      "classical: 1\n",
      "country: 2\n",
      "disco: 3\n",
      "hiphop: 4\n",
      "jazz: 5\n",
      "metal: 6\n",
      "pop: 7\n",
      "reggae: 8\n",
      "rock: 9\n",
      "\n",
      "Train Size: 800\n",
      "Test Size: 200\n",
      "[[ 0.68221918  0.06206651 -1.25032485 ...  0.06234857  0.94596436\n",
      "  -0.26275888]\n",
      " [ 0.91808318 -0.17398442  1.65686311 ... -0.24380684 -0.78406413\n",
      "  -0.38632968]\n",
      " [-1.05044203 -0.13185441  1.02940764 ...  0.01051284 -0.24352654\n",
      "   0.83540992]\n",
      " ...\n",
      " [-0.27273291 -0.48032228  2.16192977 ...  0.18069975  1.94893433\n",
      "   0.07370814]\n",
      " [ 3.19286233 -5.63096899 -0.67257058 ... -1.30557956  1.28591132\n",
      "  -1.17127214]\n",
      " [ 0.45360574 -0.48357081  1.91492653 ... -0.53359154 -0.78125525\n",
      "  -0.78827039]]\n"
     ]
    }
   ],
   "source": [
    "## Dropping / cleaning data\n",
    "\n",
    "\n",
    "df_30_sec = pd.read_csv(\"../data/features_30_sec.csv\")\n",
    "\n",
    "\n",
    "print(\"Shape all data:\", df_30_sec.shape)\n",
    "# print(df_30_sec.head())\n",
    "\n",
    "# Encode Labels\n",
    "le = LabelEncoder()\n",
    "df_30_sec['label_encoded'] = le.fit_transform(df_30_sec['label'])\n",
    "\n",
    "\n",
    "print(\"\\nCategories Encoded:\")\n",
    "for i, category in enumerate(le.classes_):\n",
    "    print(f\"{category}: {i}\")\n",
    "    \n",
    "## Splitting / Scaling data \n",
    "y = df_30_sec[\"label_encoded\"].to_numpy()\n",
    "X = df_30_sec.drop(columns=[\"filename\", \"length\", \"label\", \"label_encoded\"]).to_numpy()\n",
    "\n",
    "[X_train, X_test, y_train, y_test] = train_test_split(X, y, test_size = .2, random_state=42)\n",
    "\n",
    "print(\"\\nTrain Size:\", len(X_train[:]))\n",
    "print(\"Test Size:\", len(X_test[:]))\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 57\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "in_size = X_train.shape[1]\n",
    "print(\"Input size:\", in_size)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_size, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model_NN = Net(in_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/5000], Loss: 0.0185\n",
      "Epoch [400/5000], Loss: 0.0149\n",
      "Epoch [600/5000], Loss: 0.0138\n",
      "Epoch [800/5000], Loss: 0.0108\n",
      "Epoch [1000/5000], Loss: 0.0203\n",
      "Epoch [1200/5000], Loss: 0.0122\n",
      "Epoch [1400/5000], Loss: 0.0160\n",
      "Epoch [1600/5000], Loss: 0.0081\n",
      "Epoch [1800/5000], Loss: 0.0050\n",
      "Epoch [2000/5000], Loss: 0.0058\n",
      "Epoch [2200/5000], Loss: 0.0108\n",
      "Epoch [2400/5000], Loss: 0.0222\n",
      "Epoch [2600/5000], Loss: 0.0065\n",
      "Epoch [2800/5000], Loss: 0.0236\n",
      "Epoch [3000/5000], Loss: 0.0115\n",
      "Epoch [3200/5000], Loss: 0.0085\n",
      "Epoch [3400/5000], Loss: 0.0073\n",
      "Epoch [3600/5000], Loss: 0.0068\n",
      "Epoch [3800/5000], Loss: 0.0092\n",
      "Epoch [4000/5000], Loss: 0.0093\n",
      "Epoch [4200/5000], Loss: 0.0093\n",
      "Epoch [4400/5000], Loss: 0.0072\n",
      "Epoch [4600/5000], Loss: 0.0093\n",
      "Epoch [4800/5000], Loss: 0.0085\n",
      "Epoch [5000/5000], Loss: 0.0140\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_NN.parameters(), lr=0.05)\n",
    "\n",
    "num_epochs = 5000\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    y_pred = model_NN(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    if (i+1) % 200 == 0:\n",
    "        print(f'Epoch [{i+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7250\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model_NN(X_test_tensor)\n",
    "    _, predicted = torch.max(y_pred, dim=1)\n",
    "    accuracy = (predicted == y_test_tensor).float().mean()\n",
    "    print(f'Test Accuracy: {accuracy.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
